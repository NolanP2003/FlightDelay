{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1a200f-ad66-402e-9296-2d71dda93e00",
   "metadata": {},
   "source": [
    "# Big Data Project: Flight Delay Prediction Using Spark Streaming & Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57837d-576b-4764-8c3d-3c153b353350",
   "metadata": {},
   "source": [
    "## (1) Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542037d-4913-4de8-91cf-208e5ec622d9",
   "metadata": {},
   "source": [
    "Flight Dataset: https://www.kaggle.com/datasets/patrickzel/flight-delay-and-cancellation-dataset-2019-2023?select=flights_sample_3m.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a398605-7807-4580-b073-b3779fea373c",
   "metadata": {},
   "source": [
    "### Flight Info\n",
    "* FL_DATE - Flight Date (yyyymmdd)\n",
    "* AIRLINE_CODE - Reporting Airline / Unique Carrier Code. When the same code has been used by multiple carriers, a numeric suffix is used for earlier users, for example, PA, PA(1), PA(2). Use this field for analysis across a range of years.\n",
    "* DOT_CODE - An identification number assigned by US DOT to identify a unique airline (carrier). A unique airline (carrier) is defined as one holding and reporting under the same DOT certificate regardless of its Code, Name, or holding company/corporation.</td>\n",
    "* FL_NUMBER - Flight Number\n",
    "\n",
    "### Locations\n",
    "* ORIGIN - Origin Airport\n",
    "* ORIGIN_CITY - Origin Airport, City Name\n",
    "* DEST - Destination Airport\n",
    "* DEST_CITY - Destination Airport, City Name\n",
    "\n",
    "### Departure\n",
    "* CRS_DEP_TIME - Computer Reservation System Departure Time (local time: hhmm)\n",
    "* DEP_TIME - Actual Departure Time (local time: hhmm)\n",
    "* DEP_DELAY - Difference in minutes between scheduled and actual departure time. Early departures show negative numbers.\n",
    "\n",
    "### Takeoff/Landing\n",
    "* TAXI_OUT - Taxi Out Time, in Minutes\n",
    "* WHEELS_OFF - Wheels Off Time (local time: hhmm)\n",
    "* WHEELS_ON - Wheels On Time (local time: hhmm)\n",
    "* TAXI_IN - Taxi In Time, in Minutes\n",
    "\n",
    "### Arrival\n",
    "* CRS_ARR_TIME - Computer Reservation System Arrival Time (local time: hhmm)\n",
    "* ARR_TIME - Actual Arrival Time (local time: hhmm)\n",
    "* ARR_DELAY - Difference in minutes between scheduled and actual arrival time. Early arrivals show negative numbers.\n",
    "\n",
    "### Cancellation/Diversion\n",
    "* CANCELLED - Cancelled Flight Indicator (1=Yes)\n",
    "* CANCELLATION_CODE - Specifies The Reason For Cancellation\n",
    "* DIVERTED - Diverted Flight Indicator (1=Yes)\n",
    "\n",
    "### Flight\n",
    "* CRS_ELAPSED_TIME - Computer Reservation System Elapsed Time of Flight, in Minutes\n",
    "* ELAPSED_TIME - Elapsed Time of Flight, in Minutes\n",
    "* AIR_TIME - Flight Time, in Minutes\n",
    "* DISTANCE - Distance between airports (miles)\n",
    "\n",
    "### Delay\n",
    "* DELAY_DUE_CARRIER - Carrier Delay, in Minutes\n",
    "* DELAY_DUE_WEATHER - Weather Delay, in Minutes\n",
    "* DELAY_DUE_NAS - National Air System Delay, in Minutes\n",
    "* DELAY_DUE_SECURITY - Security Delay, in Minutes\n",
    "* DELAY_DUE_LATE_AIRCRAFT - Late Aircraft Delay, in Minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77cb623-8a4c-4a62-be9a-47202745754b",
   "metadata": {},
   "source": [
    "[1.1] Output: Dataframe Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e368a5-b4cc-42ab-ac92-d7799a6b22d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/27 16:12:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[Stage 1:=============================>                             (2 + 2) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: date (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- AIRLINE_DOT: string (nullable = true)\n",
      " |-- AIRLINE_CODE: string (nullable = true)\n",
      " |-- DOT_CODE: integer (nullable = true)\n",
      " |-- FL_NUMBER: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- ORIGIN_CITY: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- DEST_CITY: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- WHEELS_OFF: double (nullable = true)\n",
      " |-- WHEELS_ON: double (nullable = true)\n",
      " |-- TAXI_IN: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- ELAPSED_TIME: double (nullable = true)\n",
      " |-- AIR_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- DELAY_DUE_CARRIER: double (nullable = true)\n",
      " |-- DELAY_DUE_WEATHER: double (nullable = true)\n",
      " |-- DELAY_DUE_NAS: double (nullable = true)\n",
      " |-- DELAY_DUE_SECURITY: double (nullable = true)\n",
      " |-- DELAY_DUE_LATE_AIRCRAFT: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Setup Spark path\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Initialize Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FlightDelayPrediction\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "df = spark.read.csv(\"flight_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Testing Purposes: Show 1st 5 rows of dataframe\n",
    "# df.show(5)\n",
    "\n",
    "# Show schema of dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355c472-5112-459d-a663-1e9d4ade8b00",
   "metadata": {},
   "source": [
    "## (2) Data Cleaning/Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54df2e4-8467-4b72-99be-3a856530119c",
   "metadata": {},
   "source": [
    "[2.1] Output: Showing Null Counts before Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1478b7ff-7998-445e-821d-c77a7a16904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|              Column|Null_Count|\n",
      "+--------------------+----------+\n",
      "|             FL_DATE|         0|\n",
      "|             AIRLINE|         0|\n",
      "|        AIRLINE_CODE|         0|\n",
      "|              ORIGIN|         0|\n",
      "|         ORIGIN_CITY|         0|\n",
      "|                DEST|         1|\n",
      "|           DEST_CITY|         1|\n",
      "|        CRS_DEP_TIME|         1|\n",
      "|            DEP_TIME|      6993|\n",
      "|           DEP_DELAY|      6996|\n",
      "|            TAXI_OUT|      7087|\n",
      "|          WHEELS_OFF|      7087|\n",
      "|           WHEELS_ON|      7186|\n",
      "|             TAXI_IN|      7186|\n",
      "|        CRS_ARR_TIME|         1|\n",
      "|            ARR_TIME|      7186|\n",
      "|           ARR_DELAY|      7699|\n",
      "|           CANCELLED|         1|\n",
      "|            DIVERTED|         1|\n",
      "|    CRS_ELAPSED_TIME|         3|\n",
      "|        ELAPSED_TIME|      7699|\n",
      "|            AIR_TIME|      7699|\n",
      "|            DISTANCE|         1|\n",
      "|   DELAY_DUE_CARRIER|    218893|\n",
      "|   DELAY_DUE_WEATHER|    218893|\n",
      "|       DELAY_DUE_NAS|    218893|\n",
      "|  DELAY_DUE_SECURITY|    218893|\n",
      "|DELAY_DUE_LATE_AI...|    218893|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import pyspark SQL functions & ML features\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
    "\n",
    "# Dropping columns we don't need\n",
    "columns_to_drop = ['CANCELLATION_CODE', 'AIRLINE_DOT', 'DOT_CODE', 'FL_NUMBER']\n",
    "df = df.drop(*columns_to_drop)\n",
    "\n",
    "# Create a DataFrame with column names and their respective null counts\n",
    "null_counts = [(col, df.filter(df[col].isNull()).count()) for col in df.columns]\n",
    "null_df = spark.createDataFrame(null_counts, [\"Column\", \"Null_Count\"])\n",
    "\n",
    "# Show the result\n",
    "null_df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77f05fc-37f1-41be-813e-c9d16632b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that if ARR_DELAY or DEP_DELAY are null then either:\n",
    "# 1) Missing data entries\n",
    "# 2) Corrupt data entries\n",
    "# Drop null values\n",
    "df = df.dropna(subset=[\"ARR_DELAY\", \"DEP_DELAY\"])\n",
    "\n",
    "# Filling null values with 0 for these specific columns since there is no delay \n",
    "# due to these issues\n",
    "df = df.fillna({\n",
    "    'DELAY_DUE_CARRIER': 0, \n",
    "    'DELAY_DUE_WEATHER': 0, \n",
    "    'DELAY_DUE_NAS': 0, \n",
    "    'DELAY_DUE_SECURITY': 0, \n",
    "    'DELAY_DUE_LATE_AIRCRAFT': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2ee481-4ec9-405a-94b1-132ab69a491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing format of the date for easier use\n",
    "df = df.withColumn(\"FL_DATE\", F.to_date(F.col(\"FL_DATE\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# extracting time-based features from scheduled departure time (CRS_DEP_TIME) column\n",
    "df = df.withColumn(\"DEP_HOUR\", (F.col(\"CRS_DEP_TIME\") / 100).cast(\"integer\"))\n",
    "df = df.withColumn(\"DEP_DAY_OF_WEEK\", F.dayofweek(F.col(\"FL_DATE\")))\n",
    "df = df.withColumn(\"DEP_MONTH\", F.month(F.col(\"FL_DATE\")))\n",
    "\n",
    "# weekend flights most likely have higher likelihood of being delayed so we'll flag these\n",
    "df = df.withColumn(\"IS_WEEKEND\", F.when(F.col(\"DEP_DAY_OF_WEEK\").isin([1, 7]), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63c398-bcfe-40d5-8e93-7e1e92ba49ae",
   "metadata": {},
   "source": [
    "[2.2] Output: Basic Numerical Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db20c65f-206c-420a-bdfb-d9e12039533e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/27 16:13:41 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 90:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DEP_DELAY TAXI_OUT TAXI_IN ARR_DELAY AIR_TIME DISTANCE  \\\n",
      "summary                                                          \n",
      "count      258676   258676  258676    258676   258676   258676   \n",
      "mean        10.14    16.64    7.67      4.34   112.18   809.64   \n",
      "stddev      49.27     9.19    6.21      51.4    69.53   587.51   \n",
      "min         -68.0      1.0     1.0     -81.0      8.0     30.0   \n",
      "max        1732.0    172.0   222.0    1741.0    661.0   5095.0   \n",
      "\n",
      "        DELAY_DUE_CARRIER DELAY_DUE_WEATHER DELAY_DUE_NAS DELAY_DUE_SECURITY  \\\n",
      "summary                                                                        \n",
      "count              258676            258676        258676             258676   \n",
      "mean                 4.57              0.72          2.41               0.03   \n",
      "stddev              31.76             14.67         15.21               1.41   \n",
      "min                   0.0               0.0           0.0                0.0   \n",
      "max                1732.0            1398.0        1468.0              286.0   \n",
      "\n",
      "        DELAY_DUE_LATE_AIRCRAFT DEP_HOUR DEP_DAY_OF_WEEK DEP_MONTH IS_WEEKEND  \n",
      "summary                                                                        \n",
      "count                    258676   258676          258676    258676     258676  \n",
      "mean                       4.72     13.0            3.97      6.28       0.28  \n",
      "stddev                    26.42     4.83            1.99      3.38       0.45  \n",
      "min                         0.0      0.0             1.0       1.0        0.0  \n",
      "max                      1548.0     23.0             7.0      12.0        1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a list of numeric columns in dataframe\n",
    "# Not using time based: CRS_DEP_TIME/DEP_TIME, CRS_ARR_TIME/ARR_TIME, CRS_ELAPSED_TIME/ELAPSED_TIME, WHEELS_OFF/WHEELS_ON\n",
    "# Not using binary based: CANCELLED/DIVERTED\n",
    "numeric_cols = [\"DEP_DELAY\", \"TAXI_OUT\", \"TAXI_IN\", \"ARR_DELAY\", \"AIR_TIME\", \"DISTANCE\",\n",
    "                \"DELAY_DUE_CARRIER\", \"DELAY_DUE_WEATHER\", \"DELAY_DUE_NAS\", \"DELAY_DUE_SECURITY\", \"DELAY_DUE_LATE_AIRCRAFT\",\n",
    "                \"DEP_HOUR\", \"DEP_DAY_OF_WEEK\", \"DEP_MONTH\", \"IS_WEEKEND\"]\n",
    "\n",
    "# Testing Purposes: Show list of numeric columns of dataframe\n",
    "# print(numeric_cols)\n",
    "\n",
    "# Get the basic statistics of the DataFrame for the numeric columns\n",
    "df_stats = df.select([F.round(F.col(c), 2).alias(c) for c in numeric_cols]).describe()\n",
    "\n",
    "# Convert the result to a Pandas DataFrame\n",
    "df_stats_pd = df_stats.toPandas()\n",
    "\n",
    "# Round the numeric values (except for the 'summary' row)\n",
    "df_stats_pd.iloc[1:, 1:] = df_stats_pd.iloc[1:, 1:].apply(pd.to_numeric, errors='coerce').round(2)\n",
    "\n",
    "# Set the 'summary' features as the index\n",
    "df_stats_pd.set_index('summary', inplace=True)\n",
    "\n",
    "print(df_stats_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43454c8-eda9-48a5-9e9a-7a40b77f9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# severe delay for flights delayed over one hour\n",
    "df = df.withColumn(\"SEVERE_DELAY\", F.when(F.col(\"ARR_DELAY\") >= 60, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f7e920-c4fe-4a18-9e08-cff41504be45",
   "metadata": {},
   "source": [
    "## (4) Prepare Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ebc302-d64e-4a87-82ac-5878091518c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|      final_features|SEVERE_DELAY|\n",
      "+--------------------+------------+\n",
      "|(784,[4,39,412,76...|           0|\n",
      "|(784,[1,30,403,76...|           0|\n",
      "|(784,[4,20,408,76...|           0|\n",
      "|(784,[1,30,409,76...|           0|\n",
      "|(784,[11,27,396,7...|           0|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# encoding the categorical variables and adding index/onehot after them in the columns\n",
    "categorical_cols = [\"AIRLINE\", \"ORIGIN\", \"DEST\"]\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}Index\") for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{col}Index\", outputCol=f\"{col}OneHot\") for col in categorical_cols]\n",
    "\n",
    "# using vector assembler on numerical data\n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# making the final assembler\n",
    "final_assembler = VectorAssembler(\n",
    "    inputCols=[\"AIRLINEOneHot\", \"ORIGINOneHot\", \"DESTOneHot\", \"scaled_features\"],\n",
    "    outputCol=\"final_features\"\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler, final_assembler])\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "\n",
    "processed_df.select(\"final_features\", \"SEVERE_DELAY\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d6789b-8101-4485-bbef-86f60251dc8b",
   "metadata": {},
   "source": [
    "## (5) Initial Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "398b75bf-ba9d-4f8d-b73b-9f8ff5e0bd9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BinaryClassificationEvaluator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Select the final features and label\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model_df \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_df\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_features_extended\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEVERE_DELAY\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m                                 \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_features_extended\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      7\u001b[0m                                 \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEVERE_DELAY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m sample_df \u001b[38;5;241m=\u001b[39m model_df\u001b[38;5;241m.\u001b[39msample(withReplacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m101\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Train/Test split\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Select the final features and label\n",
    "model_df = final_df.select(\"final_features_extended\", \"SEVERE_DELAY\") \\\n",
    "                                .withColumnRenamed(\"final_features_extended\", \"features\") \\\n",
    "                                .withColumnRenamed(\"SEVERE_DELAY\", \"label\")\n",
    "\n",
    "sample_df = model_df.sample(withReplacement=False, fraction=0.1, seed=101)\n",
    "\n",
    "# Train/Test split\n",
    "train_df, test_df = sample_df.randomSplit([0.7, 0.3], seed=101)\n",
    "\n",
    "# RandomForest model training\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "# Predictions on test set\n",
    "predictions = rf_model.transform(test_df)\n",
    "\n",
    "# Evaluate accuracy\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy (AUC): {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
